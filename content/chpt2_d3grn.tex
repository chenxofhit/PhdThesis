\section{一种新的数据驱动的基因调控网络构建方法}
\label{sec:d3grn}

从基因表达数据推断基因调控网络~(GRNs)~是系统生物学中一个具有挑战性的基础问题。
上一章~\ref{sec:locpcacmi}~介绍了我们提出的调控网络结构推断方法,
Loc-PCA-CMI~输出的是无向网络, 很多时候我们会关注基因之间的相互作用方向。
为了弥补无方向的不足,现有的一些流行的算法将~GRNs~推理表述为回归问题,并以聚合~(ensemble)~策略获得最终的网络。
最近关于数据驱动的动态网络构建的研究, 主要是偏微分方程和机器学习相结合, 
为我们利用回归方法研究基因调控网络提供了一个新的视角。
在这项研究中,我们提出了一种数据驱动的动态网络构建方法来推断基因调控网络,命名为~D3GRN。
其中,将每个目标基因的调控关系转化为功能分解问题,并利用揭示网络相互作用的算法~(ARNI)~解决各个子问题。
为了弥补~ARNI~仅从单元级构建网络的局限性,我们采用抽样~(bootstrapping)~和基于面积的评分方法~(area-based scoring)~来推断最终的网络。
实验结果表明, 在~DREAM4和~DREAM5~基准数据集上, D3GRN~在~AUPR~这个评价指标上与最先进的算法相比具有竞争力。

\subsection{介绍}
% 基因调控在基因转录中发挥重要作用~\cite{lee2002transcriptional,harbison2004transcriptional},
% 基因分化~\cite{matsumoto2017scode},
% 细胞命运走向~\cite{chen2014single,trapnell2014dynamics},
% 复杂疾病~\cite{boyle2017expanded}。
% 揭示基因调控网络~(GRNs)~的结构一直是系统生物学跨学科领域的核心工作。
% 随着微阵列和~RNA~测序等高通量技术的出现,
% 大量的数据被产生,
% 这使得仅从基因表达数据或多类别数据推断~GRN~从基于计算方法~\cite{maetschke2013supervised}的角度变得可行。
% 然而,由于可用测量数量少且数据量大,数据噪声大,仅从基因表达数据推断~GRN~仍然存在巨大的挑战,

% 人们已经提出了各种用于~GRN推断的方法~\cite{karlebach2008modelling,le2015quantitative,huynh2018gene},
% 如基于相关和信息理论的方法,布尔网络~(BNs)、贝叶斯网络、常微分方程~(ODEs)和基于回归的方法。
% 这些方法从粒度级别上可以分为两类。
% 第一类预测基因相互作用的存在与否,仅仅给出静态网络,也就是它们仅描述拓扑信息,
% 基于相关性和信息理论的方法属于这一类。
% 其它方法属于第二类,它预测了描述拓扑和动态信息的基因相互作用的强度。
% 在~GRN~推断方法的所有类别方法中,基于~ODE~和回归的方法是两种应用最广泛的技术。

% 在基于相关和信息理论的方法中,
% 除了简单的Pearson相关性~\cite{stuart2003gene},互信息~(MI)~\cite{steuer2002mutual}是最受亲睐的度量指标之一,
% 它能够捕获成对或基因组之间的复杂的非线性和非单调动力学关系~\cite{uda2013robustness,mc2015information}。
% ARACNE~\cite{basso2005reverse}使用数据处理不等式~(DPI)来过滤掉来自三重基因的间接相互作用。
% 随后基于相同的目的,条件互信息~(CMI)~\cite{zhang2011inferring},
% 局部重叠基因簇基于条件互信息~(Loc-PCA-CMI)~\cite{8660530},
% 部分互信息~(PMI)~\cite{zhao2016part}和部分信息分解~(PID)~\cite{chan2017gene}被提出来,
% 这些方法都考虑尽可能消除假阳性或者间接调控关系。

% 在~BNs~中,基因的替代状态用离散值~0~(无效)和~1~(有效)表示,
% 调节相互作用由布尔逻辑~\cite{kauffman1969homeostasis}描述。
% 概率布尔网络~(PBNs)~\cite{shmulevich2002probabilistic}将概率引入标准~BN~以表达调控逻辑中的不确定性。
% 典型的演变方法,例如随机布尔网络~(SBNs)~\cite{liang2012stochastic},
% 旨在提高~PBN~的计算性能。
% BNs的弱点是模型只考虑离散状态的基因。
% 因此,无法有效捕获真实基因表达中蕴含的详细信息。

% 贝叶斯网络,包括传统的贝叶斯网络~\cite{friedman2000using,friedman2003being}
% 和动态贝叶斯网络~(DBN)~\cite{grzegorczyk2010improvements},
% 基于概率和图论对基因调控过程进行建模。
% 贝叶斯网络将基因的规则视为随机变量之间的依赖概率,并从基因谱中学习最佳结构。
% 尽管最近取得了一些进展~\cite{hill2012bayesian},贝叶斯网络仍然具有相当大的计算开销,
% 不适用于大型全基因组数据集。

% ODE~提供了对调节动力学的无穷小描述~\cite{chen1999modeling},
% 通过将基因的变化率(时间导数)与其表达值联系起来。
% Inferelator~\cite{bonneau2006inferelator},
% S~系统模型~\cite{kikuchi2003dynamic,wang2010inference,liu2012inference}是~ODE~中的典型方法。
% 通常,基于~ODE~的方法通过利用大参数空间估计而是灵活的。
% 结果,类似于贝叶斯网络,需要巨大的计算来完成任务。

由于~DREAM~系列竞赛的推动,利用机器学习回归模型进行基因调控网络的构建方法大量涌现。
这类方法本质上可以看作是关联网络模型的延伸,
与关联网络只关注量化相互作用不同的是回归方法能够推断出基因之间的相互作用方向。
回归模型将基因调控建模转化为机器学习特征选择的问题,
即是将靶标基因的表达看作是调控基因表达之间的相互线性作用或者非线性作用的结果,
采用~bagging~或者~boosting~的做法,推断出最终的基因调控网络。
GENIE3~\cite{huynh2010inferring}~被认为是在一些基准数据集的最好方法~\cite{marbach2010revealing},
这个方法基于随机森林模型训练了一个回归模型为每个基因选择最重要的调控因子。
在~GENIE3~基础上,~GRNBoost2~\cite{moerman2019grnboost2}~做了扩展, 适合于有成千上万个基因的大规模数据集。
所不同的是,它是通过使用随机梯度增强的机器学习回归方法来做特征选择, 
加入正则化和``early stop”~机制来防止模型过拟合。 
TIGRESS~\cite{Haury2012}~使用最小角度回归~(LARS)~稳定选择结合起来解决~GRN~推断问题。
NIMEFI~\cite{ruyssinck2014nimefi}~探讨了几种聚合方法的潜力,
例如~GENIE3,~集成支持向量回归~(E-SVR)和~集成弹性网络~(E-EL)~\cite{zou2005regularization},
并在一般框架下结合这些方法的预测。
bLARS~\cite{singh2016blars}可以被视为~TIGRESS~的变形方法,
其中调控关系是从预定义的基础函数建模的, 并且通过修改的~LARS~算法获得最终的~GRN。

最近,数据驱动的动态网络构建尤其是在物理系统中是一个非常有吸引力和有趣的话题。
SINDy~\cite{brunton2016discovering}~假设只有少数重要变量可以控制动态系统,
因此,偏微分方程在可能的函数空间中是稀疏的。
然后,它使用稀疏回归来确定准确表示数据所需的动态控制方程中的最少项。
ARNI~\cite{casadiego2017model}~是一个独立于模型的框架,用于推断网络动态系统中的直接交互作用,
这仅依赖于他们的非线性聚合动力学。
它通过函数分解和基函数的展开来求解非线性微分方程组。

虽然~bLARS,~SINDy~和~ARNI~是在不同的研究领域提出来的,
它们的基本思想十分相似。
表~\ref{comparision}~是从三个不同方面对这三个方法进行比较。
形式化函数分解~(formal function  decomposition)~意味着该方法是否具有函数分解方程的形式描述;
稀疏组约束~(sparse group  constraints )~指示该方法是否利用候选项的稀疏组约束,
而基于网络的构造~(network based construction)~表明该方法是否旨在重建整个网络结构。
~SINDy~和~ARNI~都没有解决从网络层面发现物理机制的问题,但仅来自节点级别。
由于没有一种方法都结合​​这三点,
所以在本研究中,我们第一次尝试将上述三个方面合为一体,提出了一种新的数据驱动的动态网络构建方法。
~D3GRN~将每个靶基因的调节关系转化为功能分解问题并以特征选择的方式解决每个子问题,
通过使用~ARNI~算法揭示网络相互作用结构。
使用基于面积的评分方法通过自举策略推断整个网络结构。
我们在~DREAM4~和~DREAM5~基因调控网络重建竞赛数据集上将方法~D3GRN~与其它几种当今最优秀的方法进行比较,
结果表明~D3GRN~在~AUPR~上具有优势。

\begin{table}[!htbp]
    %\caption{Comparison of the related methods}
    \caption{相关方法比较}
    \centering
%    \begin{adjustbox}{max width=0.5\textwidth}
    \label{comparision}  
    \begin{tabular}{lccccc}
    \toprule
    &bLARS &SINDy&ARNI&D3GRN\\
    \midrule
    formal function  decomposition &$\times$ &\checkmark &\checkmark&\checkmark\\ 
    sparse group  constraints &\checkmark &$\times$ &\checkmark&\checkmark\\
    network based construction&\checkmark&$\times$ &$\times$&\checkmark\\
    \bottomrule                   
    \end{tabular}
  %  \end{adjustbox}
\end{table}

\subsection{方法}
\subsubsection{问题定义}

如果不考虑基因之间的上游或下游调节关系并且忽略自我调节机制,则可以将~GRN~视为有向无环图~(DAG)。
在~DAG~中,每个节点对应于基因,并且每个边缘代表基因之间的调节关系。
和许多其它聚合方法一样~(例如~\cite{huynh2010inferring,Haury2012,slawek2013ennet,ruyssinck2014nimefi,guo2016gene,zheng2019ensemble}),
它不利用不同实验条件的信息~(例如,基因敲除,扰动甚至重复),
我们仅基于基因表达数据使用~GRN~推理问题的通用框架。
作为输入基因表达数据,我们考虑在~$M$~实验条件下测量~$N$~基因的表达量。
因此,基因表达数据~$A$~定义如下:
\begin{equation}
\label{eq:definion}
A = [x_1,x_2,\ldots,x_N] \in \mathbb{R} ^ {M \times N}
\end{equation}
其中~$x_i$~是所有~$M$~实验条件中第~$i$~个基因的表达值的列向量。

GRN~推断方法预测基因表达数据基因之间的调节联系~$A$。
大多数方法提供了从最高到较低置信度的潜在调控关系的排名列表。
随后可以通过在该排序列表上选择变化的阈值来获得不同的~DAG。
因为最终用户有利于探索各种类型的网络阈值水平~\cite{slawek2013ennet},
我们只关注本研究中的排名问题。
值得注意的是,排名是``逆向工程对话评估和方法"~(DREAM)~\cite{stolovitzky2007dialogue}竞赛的标准预测格式,
其中已经提出了各种~GRN~推断方法。
此外,我们不考虑从排名中获得的网络的稳定性。

为了从表达数据~$A$~推断出调控网络,
我们计算一个权重分数~$S_{ij}$,
用于从基因~$i$~到基因~$j$~的潜在边,
边表示基因~$i$~在表达水平上调节基因~$j$~并且权重分数~$S_{ij}$~代表基因~$i$~调控的强度~(包括上调和下调)基因~$j$。

\subsubsection{基于集成回归方法的网络推理}
受基于特征选择的集成方法~(例如~GENIE3~\cite{huynh2010inferring}和~TIGRESS~\cite{Haury2012})~成功应用的启发,
$n$~个基因的~GRN~推断问题可以分解为~$n$~个子问题,
其中每个子问题都可以看作是机器学习中的特征选择问题~\cite{nasrabadi2007pattern}。
更具体地说,对于每个目标基因,我们希望从表达水平上确定直接影响它的基因子集。
设~$A$~是等式~(\ref{eq:definion})~中定义的基因表达数据,
第~$i$~个基因为靶基因,我们在~$M$~个实验条件~(即样本)~下定义了其它候选表达调节因子:
\begin{equation}
  \label{eq:x}
  x^{-i} = [x_1,\ldots,x_{i-1},x_{i+1},\ldots,x_N]
  \end{equation}

特征选择问题可以定义为:
\begin{equation}
\label{eq:fs}
x_i =  F(x^{-i}) + \epsilon , \forall i \in \{1,2,\ldots,N\}
\end{equation}
其中,~$F$~是任意一个平滑, 典型的如~$x^{-i}$~个基因~(也就是跟基因~$i$~相关的基因)~表达值的非线性函数;$\epsilon$~是噪声项~\cite{huynh2010inferring,Haury2012}。
% Generally, the function $F$ is unknown which can be defined indirectly as:
% \begin{equation}
% \label{eq:ffunction}
% F(x^{-i}) = \sum_{1}^{n} w_{ji}x_j , \forall j \in \{1,\ldots,i-1,i+1,\ldots,n\}
% \end{equation}
% where $w_{ji}\geqslant 0$ represents the strength~(or confidence) that gene $i$ associates (i.e., regulates) gene $j$. 
% The rankings of the regulatory links of gene $i$ is obtained by computing the $w_{ji}$.
把~$N$~个独立的基因排名聚合起来,我们能得到一个全局的~GRN~的调控关系的排名。

\subsubsection{使用~D3GRN~进行~GRN~推断}

~D3GRN算法的伪代码如算法~\ref{alg:D3GRN}~所示。
$A_j$~指的是矩阵~$A$的第~$j$~列, 
$A_I$~是~$A$~中包含索引列集合~$I$~的子矩阵。

假定,输入的基因表达矩阵~$A \in \mathbb{R}^{M \times N}$, 
并且转录因子的索引~$I \subset \{1,\ldots,N\}$, 
同时抽样数目和~ARNI~算法的步数~$L$~已经知道。
那么对于每一个目标基因~$j$, 第~$i$~次抽样,
通过在~$A$~中放回重复抽样,
对应的目标基因~$j$~的表达值为~$y$, 
其它的转录因子~$X$~的表达值也获取到。
ARNI~算法被调用后,返回的是被选中的调控因子~$SM_j$~的一个有序列表~(ordered list)。
最后,在所有的~$b$~轮抽样结束后,
矩阵~$SM$~作为输入变量,通过基于面积的打分方法,
给一个候选的转录因子和目标基因之间的边~0~和~1~之间的分数。
抽样和基于面积的打分方法的细节,以及计算复杂度分析,在后续的章节中会详细描述。
 
\begin{algorithm}
  %\caption{D3GRN Pseudo Code}
  \caption{D3GRN~算法伪代码}
  \label{alg:D3GRN}
  \begin{algorithmic}[1]
  \Require $A \in \mathbb{R}^{M \times N}$, $I \subset \{1,\ldots,N\}$, 
            $|I| = n$                                   \Comment{$M$ samples, $N$ genes, I index set of $n$ regulators}
  \Ensure $b$, $L$                                      \Comment{Number of bootstrapping runs and ARNI steps}
  \State Initialize $S \in \mathbb{R}^{N \times n}$     \Comment{Initialize adjacency matrix of the GRN}
  \State Initialize $SM \in \mathbb{R}^{n \times b}$     \Comment{Initialize the selection matrix}
  \For{$i = 1 \to b$}                                   \Comment{For each bootstrapping run}
        \State $A^{*}$ = resample$(A)$                  \Comment{Resampling with replacement}
        \For{$j = 1 \to n$}                             \Comment{For each target gene}         
        \State $y = A^{*}_j, X = A^{*}_{I\setminus j}$
        \State $SM_{ji}$ = ARNI$(y,X,L)$                    \Comment{Returns selected tx-factors with the ARNI algorithm}
        \EndFor
  \EndFor           
  \State $S$ = area-score$(SM,L,b)$                      \Comment{Get the weight score matrix with the area-score metric}
  \State Output: $S$                                    \Comment{Output the score matrix}
\end{algorithmic}
\end{algorithm}


\subsubsection{基于~ARNI~的特征选择}

对于给定节点~$i$~及其对应的微分方程, 
ARNI~转向获得哪些节点~$j$~的网络提供了直接的物理相互作用, 并出现在等式的右侧, 
而不是探索方程中这些节点之间的交互函数的细节。

详细地, 对于~$N$~个节点的动态系统, 
ARNI~首先将单元~$i$~的动态性分解为与网络中其它单元的交互项~\cite{casadiego2017model}:
\begin{equation}
\label{eq:xi}
\begin{split}
% \dot{x_i}= & f_i(\Lambda ^i x)\\
%          = &\sum_{j=1}^{N} \Lambda^i_{jj} g^i_j(x_j) + 
%                              \sum_{j=1}^{N} \sum_{s=1}^{N}\Lambda^i_{jj}\Lambda^i_{ss}g^i_{js}(x_j,x_s)\\
%          + &\sum_{j=1}^{N} \sum_{s=1}^{N} \sum_{w=1}^{N}\Lambda^i_{jj}\Lambda^i_{ss}\Lambda^i_{ww}g^i_{jsw}(x_j,x_s,x_w)+ \ldots + \epsilon_{i}
% \end{split}
\dot{x_i}= & f_i(\Lambda ^i x)\\
         = &\sum_{j=1}^{N} \Lambda^i_{j} g^i_j(x_j) + 
                             \sum_{j=1}^{N} \sum_{s=1}^{N}\Lambda^i_{j}\Lambda^i_{s}g^i_{js}(x_j,x_s)\\
         + &\sum_{j=1}^{N} \sum_{s=1}^{N} \sum_{w=1}^{N}\Lambda^i_{j}\Lambda^i_{s}\Lambda^i_{w}g^i_{jsw}(x_j,x_s,x_w)+ \ldots + \epsilon_{i}
\end{split}
\end{equation}

其中~$\dot{x}_i :=[\dot{x}_{i,1}, \dot{x}_{i,2},\ldots,\dot{x}_{i,M}]\in \mathbb{R}^M$,
$f:\mathbb{R}^N \to \mathbb{R}$~是一个平滑函数, 
对角矩阵~$\Lambda^i \in \{0,1\}^{N \times N}$~和~$\Lambda^i_{j}=1$~如果~$j$~直接作用于~$i$, 
否则~$\Lambda^i_{j}=0$,~$g^i_j:\mathbb{R} \to \mathbb{R}$, $g^i_{js}:\mathbb{R}^2 \to \mathbb{R}$, $g^i_{jsw}:\mathbb{R}^3 \to \mathbb{R}$,
并且一般~$g^i_{j_{1}j_{2}\ldots\\j_{K}}:\mathbb{R}^K \to \mathbb{R}$~表示(未知)单元~$j_k$~($k \in \{1,2,\ldots,K\}$)~和单元~$i$~的第~$K$~阶相互作用, 
最后一项~$\epsilon_{i}$~代表于作用于~$i$~的额外噪声。

函数~$g^i_{j_{1}j_{2}\ldots\\j_{K}}$~无法访问,可以将其分解为基函数~$h$,
我们可以将等式~(\ref{eq:xi})~重写为~\cite{casadiego2017model}。
\begin{equation}
\label{eq:xi_with_h}
\begin{split}
% \dot{x_i} =  &\sum_{j=1}^{N} \Lambda^i_{jj} \sum_{p=1}^{P_1} c^i_{j,p}h_{j,p}(x_j) \\
% + &  \sum_{j=1}^{N} \sum_{s=1}^{N}\Lambda^i_{jj}\Lambda^i_{ss} \sum_{p=1}^{P_2} c^i_{js,p}h_{js,p}(x_j,x_s) \\
%                              + &\sum_{j=1}^{N} \sum_{s=1}^{N} \sum_{w=1}^{N}\Lambda^i_{jj}\Lambda^i_{ss}\Lambda^i_{ww} \sum_{p=1}^{P_3} c^i_{jsw,p}h_{jsw,p}(x_j,x_s,x_w)\\
%                              + &\ldots + \epsilon_{i} 
% \end{split}
\dot{x_i} =  &\sum_{j=1}^{N} \Lambda^i_{j} \sum_{p=1}^{P_1} c^i_{j,p}h_{j,p}(x_j) \\
+ &  \sum_{j=1}^{N} \sum_{s=1}^{N}\Lambda^i_{j}\Lambda^i_{s} \sum_{p=1}^{P_2} c^i_{js,p}h_{js,p}(x_j,x_s) \\
                             + &\sum_{j=1}^{N} \sum_{s=1}^{N} \sum_{w=1}^{N}\Lambda^i_{j}\Lambda^i_{s}\Lambda^i_{w} \sum_{p=1}^{P_3} c^i_{jsw,p}h_{jsw,p}(x_j,x_s,x_w)\\
                             + &\ldots + \epsilon_{i} 
\end{split}
\end{equation}
其中,~$P_k$~表示扩展函数中采用的基函数数目~\cite{friedman2001elements}。
$c^i_{j,p}$,~$c^i_{js,p}$,~$c^i_{jsw,p}$~为未知系数。
适当的基函数~$h$~有利于形成相关的函数空间。
例如,对偶基函数类~$g^i_{ij}(x_i,x_j)$~可以是~$h^i_{ij,p}(x_i,x_j)=(x_j-x_i)^p$~或~$h^i_{ij,p}(x_i,x_j)=x^{p_{1}}_i x^{p_{2}}_j$~等形式。


需要注意的是, 该框架旨在揭示动态系统中各单位的直接交互作用,尤其是时间序列数据。
对于~GRN~推理问题,尤其是来自非时间序列数据的推理,
可以对等式~(\ref{eq:xi_with_h})~做一个修改。
更特别的是,将等式~(\ref{eq:xi_with_h})~中左边的时变项~$\dot{x_i}$~替换为一个非时间变化的项~$x_i$, 注意这是一个矢量。
不考虑自我作用的同时,修改后的方程可以定义为:
\begin{equation}
\label{eq:x_i_fs}
% \begin{split}
% x_i = &\sum_{j=1}^{N} \Lambda^i_{jj} \sum_{p=1}^{P_1} c^i_{j,p}h_{j,p}(x_j)\\  
%     + &\sum_{j=1}^{N} \sum_{s=1}^{N} \sum_{w=1}^{N}\Lambda^i_{jj}\Lambda^i_{ss}\Lambda^i_{ww} \sum_{p=1}^{P_3} c^i_{jsw,p}h_{jsw,p}(x_j,x_s,x_w)\\
%     +&\ldots + \epsilon_{i}, \forall jj,ss,ww \in \{1,\ldots,i-1,i+1,\ldots,N\}
% \end{split}
\begin{split}
   x_i = &\sum_{j=1}^{N} \Lambda^i_{j} \sum_{p=1}^{P_1} c^i_{j,p}h_{j,p}(x_j)\\  
       + &\sum_{j=1}^{N} \sum_{s=1}^{N} \sum_{w=1}^{N}\Lambda^i_{j}\Lambda^i_{s}\Lambda^i_{w} \sum_{p=1}^{P_3} c^i_{jsw,p}h_{jsw,p}(x_j,x_s,x_w)\\
       +&\ldots + \epsilon_{i}
   \end{split}
\end{equation}

从等式~(\ref{eq:xi_with_h})~到等式~(\ref{eq:x_i_fs})~的转换是合理的。
在这种情况下,等式~(\ref{eq:x_i_fs})~就是等式~(\ref{eq:fs})~的详细实现。
重构问题就变成了识别等式~(\ref{eq:x_i_fs})~中的非零相互作用项。
系数向量~$c^i_{j,p}$,~$c^i_{js,p}$,~$c^i_{jsw,p}$~是未知的,
阻碍了~$\Lambda^i$~的计算。
在等式~(\ref{eq:x_i_fs})~中加上一个由零和非零系数组成的块状结构约束即可,
分别代表不存在和现有的相互作用。
这些结构化的解是由沿~$c^i$~分布的非零条目~(代表作用于单位~$i$~的非零交互作用)的块~$c^i_s$~构成的。
提出了揭示网络交互作用的算法~(ARNI)~来解决这个数学分组变量的回归问题。
这是一种基于块正交最小二乘~(BOLS)~算法的贪心方法~(greedy method)~\cite{majumdar2009fast}。
ARNI~在本质上可以看作是一种合适的特征选择方法。
与著名的~Sparse Group Lasso~\cite{friedman2010note}~相同。
算法的细节在文献~\cite{casadiego2017model}~的附件中详细解释。

\subsubsection{抽样~(bootstrapping)}

D3GRN~算法采用抽样方法,以获得更可靠的目标基因的调控因子选择。
一般来说,抽样~\cite{efron1994introduction}~是用于从经验分布的中估计参数。
抽样~\cite{efron1994introduction}~从经验分布中产生多组样本。
通过从观察样本中重采样, 然后计算每个重采样集里面的未知参数。
最后, 通过对所有重新采样的集合进行平均,就可以得到有关参数的估计值。
在重采样中, 从观察样本中随机抽取样本~(均匀随机,有替换)。
重采样技术经常被应用于在欠确定问题的情况下得到稳定的结果~\cite{wang2011random}。
在当前的~D3GRN~实现中,抽样运行~$b$=200~次。
在每次抽样过程中, 
~$y$~和~$X$~是从给定的基因表达数据中均匀随机选择重新采样与替换。
随后,~ARNI~算法被用来选择这些抽样的调节因子。
所有抽样运行的结果使用基于面积的评分~\cite{Haury2012}~技术进行汇总。
需要注意的是,~D3GRN~算法只应用抽样方法来获得每个目标基因的高置信度调控因子,
并不是同~\cite{Haury2012}~那样在许多抽样网络上进行汇总。

\subsubsection{基于面积的评分}
基于面积的评分法~(area-based scoring,~\cite{singh2016blars})~是根据它在指定的抽样运行次数中的频率,给每个候选调控因子打分。
在每次抽样运行中, 
~ARNI~提供的目标基因的调控因子的有序列表在数学上是独立的。
这种评分方法旨在利用选择的调控因子的整体排序信息。
这是通过基于面积的评分方法实现的,具体如下所述。

设~$\phi_{ijl}$~为第~$j$~个调控因子在~ARNI~的第~$l$~步中的累积选择频率。
$l={1,\ldots,L}$,显然~$\phi_{ijl}$~在~$[0,1]$。
平均值取所有抽样运行的平均值, 
基因~$i$~的调节因子~$j$~在总~$L$~步数中的得分~$S_{ij}$~定义为:
\begin{equation}
\label{eq:scoring}
S_{ij} = \frac{1}{L} \sum_{l=1}^{L} \phi_{ijl}
\end{equation}

例如,假定~$\phi_{ij1}=0.3$,~$\phi_{ij2}=0.5$,~$L=5$。
在第~5~个步骤中,第~$j$~个调控因子在第一个~ARNI~步骤中~30\%~的次数被选择,
在第二个~ARNI~步骤中~20\%~的次数被选择,那么累计选择频率~$\phi_{ij2}$~为~50\%。
分数~$S_{ij}$~有一个自然的解释,即由总面积~L~归一化的累积选择频率曲线下的面积。
%在~GRN中,得分~$s_j$代表调节器~$j$和目标基因~$i$的调控边的大小~$w_{ji}$,这在等式~(\ref{eq:function})中有所描述。
显然,这个分数不仅考虑了转录因子的总体选择频率,而且还倾向于奖励早期选择到的~ARNI~步骤。
与基于整体选择频率~$\phi_{ij}$~的简单排名相比,这种方法对~ARNI~步骤数的敏感性较低。

\subsubsection{计算复杂度}

算法的计算复杂度主要取决于~ARNI,每个目标基因需要~$O(t^2*(tp)^3)$。
其中~$t$~为转录因子的数目,~$p$~为基本函数的数目~(即方程~(\ref{eq:xi_with_h})中的~$P_k$)。
$O((tp)^3)$~是由于~BOLS~算法的~Moore-Penrose~伪逆复杂性。
因此,该算法的总体计算复杂度为~$O(t^5p^3nb)$。
其中,~$n$~是目标基因的数量,~$b$~是抽样数,由于~$t$~通常比~$n$~小得多,时间复杂度的上界是~$O(n^6p^3b)$。
由于~$t$~通常比~$n$~小得多, 所以时间复杂度的上界是~$O(n^6p^3b)$。
算法~\ref{alg:D3GRN}中的``for''循环是完全可以并行的,可以在多核甚至分布式集群机器上同时进行。


\subsection{实验结果}
\subsubsection{输入数据}
在过去十年中,~GRN~推理一直是一个相当活跃的研究领域。
因此,一个名为``逆向工程对话"的社区联合体~(DREAM)\cite{stolovitzky2007dialogue}成立,
在过去十年中一直在积极地研究~GRNs~推理。
DREAM~联盟举办国际逆向工程挑战赛, 提供标准化的通用输入数据集和性能评估指标来比较不同的方法。
该组织提供的数据集成为了~GRN~推理领域的金标准, 经常用于评估新算法的性能。

在实验中,
我们使用~DREAM4~和~DREAM5~挑战赛中的~6~个模拟数据集~\cite{marbach2012wisdom}。
数据集详情如表~\ref{datasets}~所示,其中~Network~表示~数据集名称,
\#Genes~表示基因的数量, \#Regulators~表示调控因子的数量, \#Samples~表示样本的数量, 
\#Verified interactions~表示网络中的有向调控边数。
如果一个数据集用矩阵表示,那么行表示样本,列表示基因。
我们采用~DREAM4~挑战赛中的~5~个多因素数据集,
每个包含~100~个基因和~100~个样本。
这~5~个数据集中的样本是通过从原始数据中同时微扰动所有基因表达值, 借助于使用开源的~GeneNetWeaver~软件~\cite{marbach2009generating}生成的。
因此,这~5~个数据集中的每个样本都代表了一个多因素扰动实验。
调控因子可以被看作是自己,因为在这些小网络中并没有明确指定谁是调控因子。
%此外,我们从~DREAM5~数据集中选用了三个不同的和大小变化的网络。
我们还采用了一个~DREAM5~数据集~1,这也是一个由~GeneNetWeaver~模拟生成的网络。
这个模拟网络的拓扑结构是基于模型生物的已知~GRNs。
与~DREAM4~中的网络不同的是,
DREAM5~数据集中的转录因子~(TFs)~是作为调控因子显式提供的,它是提供的所有基因中一个子集。

% while the other two expression datasets are real expression data collected 
% for E. coli (Network 3) and S. cerevisiae (Network 4). 
% It is observed that the performance of previous studies imply that Network 3 and Network 4 
% tend to be almost in a random manner.
% Accordingly, we only employ Network 1 dataset from DREAM5 datasets.
%as Network 3 and Network 4 in DREAM5 are more sparser than Network 1,
% Network 2 of DREAM5 is neglected in our experiments, 
% because there are no verified interactions provided for this dataset. 
% Network 3 and Network 4 in DREAM5 are more sparser than Network 1, 
% as they own more genes and regulators but less interactions.

\begin{table}[!htbp]
\centering
%\caption{Detail of the datasets}
\caption{实验数据集详情}

\label{datasets}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lccccc}
\toprule
Network           & \#Genes & \#Regulators & \#Samples & \#Verified interactions \\
\midrule
DREAM4  Network 1  & 100     & 100                & 100       & 176                      \\
DREAM4  Network 2  & 100     & 100                & 100       & 249                      \\
DREAM4  Network 3  & 100     & 100                & 100       & 195                      \\
DREAM4  Network 4  & 100     & 100                & 100       & 211                      \\
DREAM4  Network 5  & 100     & 100                & 100       & 193                      \\
%\hline
DREAM5 Network 1   & 1643    & 195                & 805       & 4012                   \\
%DREAM5 Network 3~(E. coli)       & 4511    & 334                & 805       & 2066                     \\
%DREAM5 Network 4~(S. cerevisiae) & 5950    & 333                & 536       & 3940                     \\
\bottomrule                   
\end{tabular}
}
\end{table}

\subsubsection{效果评价指标}

为了评估~GRN~推理算法的效果,我们使用准确率-召回率曲线下的面积~(AUPR)~作为评价指标。
除了~AUPR~之外,受试者特性曲线下的面积~(AUROC)~也被广泛用于评估效果。
一般来说,~AUROC~和~AUPR~值越高,说明~GRN~预测越准确。
需要注意的是,在稀疏的生物网络中,不存在的边数目~(阴性边)大大超过现有边的数量~(阳性边),
因而~AUPR~比~AUROC~\cite{saito2015precision}~更有参考价值。

我们首先通过比较金标准网络中的调节边和~D3GRN~的排序列表输出前~$q$~条边,
计算出真阳性~(TP)、真阴性~(TN)、假阳性~(FP)~和假阴性~(FN)~边的数量。

%The ROC curve is constructed by plotting the true positive rates~(TPR = TP/(TP + FN)) versus the false positive rates~(FPR = FP/(FP + TN)) for increasing $q$~($q = 1,2,\ldots,m^2$).
精确度-召回曲线是通过绘制精确度~$\frac{\text{TP}}{\text{TP + FP}}$~与召回度~$\frac{\text{TP}}{\text{TP + FN}}$~在增加~$q$~的情况下构建的。
~$q = 1,2,\ldots,N\times(N-1)$,其中~$N$~为基因数。
通过计算曲线下的面积得到~AUPR。
%Similarly, the precision~(TP/(TP + FP)) and recall~(TP/(TP + FN)) curve is plotted for increasing $q$.

\subsubsection{D3GRN的实验结果}
等式~(\ref{eq:xi_with_h})~中基函数的类型、阶数~$K$~和基函数的数量~$P_k$~在~ARNI~中的模型分解中起着至关重要的作用。
对于一大类动态系统,使用多项式非线性是充分的~\cite{mangan2016inferring}。
作为参考,在我们基因调控网络的构建中,也采用了多项式基函数,
形式为~$h_{j,p}(x_j)=x_j^p$,基函数的数目表示为: 
\begin{equation}
P_k=\left\{\begin{matrix}
5,  k=1\\ 
0,  k>1
\end{matrix}\right. 
\end{equation}
这隐含表达了我们不考虑一个目标基因的~2~阶及以上的阶的交互作用。
事实上,~bLARS~\cite{singh2016blars}~只考虑了一阶交互作用。
我们在本研究中也遵循这种简化的方式。
换句话说,其它基因对目标基因的调控是基于多项式非线性函数的混合。

D3GRN中有两个参数,
包括抽样运行的次数~$b$~和~ARNI~步数~$L$。
图~\ref{fig:performance_dr5}~展示了通过改变~DREAM5~网络1的~ARNI~步数和抽样运行次数这两个参数的结果。
一般来说,较大的抽样运行次数~$b$~运行时间越长,但是它的性能会越趋于稳定和优异。
然而,D3GRN~的性能对抽样运行次数相当稳定,只要它大于某一阈值,通常是~200~次左右。
对于~ARNI~的步数~$L$,一个直觉是如果~$L$~接近网络中先验的平均调控因子的数量,
那么结果将是最佳的,可以用~$\frac{2  \times \#\text{Verified interactions}}{\#\text{Genes}}$~估计到。
 
\begin{figure}[!htbp]
\centering
\input{figperformance.tex}
%\caption{AUPR by varying ARNI steps $L$ and the bootstrapping number $b$ in DREAM5  Network 1.}
\caption{
在~DREAM5~网络1~上不同的~ARNI~步骤数~$L$~和抽样数目~$b$~取得的~AUPR~值}

\label{fig:performance_dr5}
\end{figure}

我们在~DREAM4~和~DREAM5~网络进行了两次对比实验,来评测我们提出的方法~D3GRN。
NIMEFI~用~R~实现,而~GENIE3、TIGRESS~和~PLSNET~用~Matlab~实现。
这些方法的代码从对应论文提供的~URL~进行下载,在实验中各方法中的参数使用它们代码注释中提供的默认值。
我们提出的方法~D3GRN~也是在~Matlab~中实现的,使用的数据集及代码公开在仓库~\url{https://github.com/chenxofhit/D3GRN}上。

表~\ref{tab:performance_dr4}~列出了~D3GRN~与其它~GRN~推理方法在五个~DREAM4~网络上比较的结果。
其中,~D3GRN~的参数是在抽样数~$b=200$,~ARNI~步数~$L=2$~下得到的。
如表所示,除了在~DREAM4网络~2~上,~D3GRN~跟其它方法相比~AUPR~值最高。

表~\ref{tab:performance_dr5}~总结了~D3GRN~与其它网络的比较结果。
GRN推理方法在~DREAM5~数据集上的应用。
在参数设置为抽样数~$b=200$~的情况下,得到~D3GRN~的结果。
网络~1~的~ARNI步数~$L=5$。
D3GRN~在网络~1~上跟其它方法相比~AUPR~值也最高。

% \begin{table*}[!htbp]
%   %\resizebox{\columnwidth}{!}{%
%   \centering
%   \begin{threeparttable}  
%   \caption{Performance comparisons of different GRN inference methods on the DREAM4 networks, challenge size 100 Multifactorial}  
%   \label{tab:performance_dr4} 
%     \begin{tabular}{ccccccccccc}  
%     \toprule  
%     \multirow{2}{*}{Method}&  
%     \multicolumn{2}{c}{Network 1}&\multicolumn{2}{c}{Network 2}&\multicolumn{2}{c}{Network 3}&\multicolumn{2}{c}{Network 4}&\multicolumn{2}{c}{Network 5}\\
%     \cmidrule(lr){2-3} \cmidrule(lr){4-5}  \cmidrule(lr){6-7}  \cmidrule(lr){8-9} \cmidrule(lr){10-11}
%     &AUPR&AUROC &AUPR&AUROC &AUPR&AUROC &AUPR&AUROC &AUPR&AUROC\\
%     \midrule  
%     GENIE3  &0.161 &0.750        &0.154&0.734         &0.234&0.776          &0.211&0.800         &0.200&0.795    \\
%     TIGRESS &0.158 &0.747        &0.161&0.703         &0.233&0.761          &0.225&0.774         &0.233&0.754     \\
%     NIMEFI  &0.157 &\textbf{0.758}        &0.157&0.731         &0.248&0.776          &0.225&0.806         &0.241&\textbf{0.801}     \\
%     PLSNET  &0.118 &0.713        &\textbf{0.290}&\textbf{0.828}         &0.202&\textbf{0.794}          &0.228&\textbf{0.819}         &0.206&0.786     \\
%     \textbf{D3GRN}    &\textbf{0.175} &0.704        &0.136&0.683         &\textbf{0.253}&0.734          &\textbf{0.255}&0.778         &\textbf{0.247}&0.732     \\
%     \bottomrule  
%     \end{tabular}  
%    \end{threeparttable}
%  %   }
% \end{table*} 

\begin{table}[!htbp]
  %\resizebox{\width}{0.8}{%
  %\resizebox{\textwidth}{20mm}{
  \centering
  \begin{threeparttable}  
%  \caption{Performance comparisons of different GRN inference methods on the DREAM4 networks in terms of AUPR}
  \caption{不同~GRN~推理方法在~DREAM4~网络上的~AUPR~比较}

  \label{tab:performance_dr4} 
    \begin{tabular}{cccccc}  
    \toprule  
    Method
     & Network 1&  Network 2&  Network 3&  Network 4 & Network 5\\
    \midrule  
    GENIE3  &0.161   &0.154           &0.234      &0.211          &0.200                 \\
    TIGRESS &0.158   &0.161           &0.233      &0.225          &0.233                \\
    NIMEFI  &0.157   &0.157           &0.248      &0.225          &0.241                \\
    PLSNET  &0.118   &\textbf{0.290}  &0.202      &0.228          &0.206                \\
    \textbf{D3GRN}   &\textbf{0.175}  &0.136      &\textbf{0.253} &\textbf{0.255}       &\textbf{0.247}  \\
    \bottomrule  
    \end{tabular}  
   \end{threeparttable}
  %}
\end{table} 

\begin{table}[!htbp]
% \scalebox{0.6}{
% \begin{minipage}{2\linewidth}  
  %\centering  
  %\fontsize{6.5}{8}\selectfont  
   % \resizebox{\columnwidth}{!}{%
  \begin{threeparttable}  
%  \caption{Performance comparisons of different GRN inference methods on the DREAM5 Network 1 in terms of AUPR}  
  \caption{不同~GRN~推理方法在~DREAM5~网络~1~上的~AUPR~比较}

  \label{tab:performance_dr5} 
    \begin{tabular}{ccccccc}  
    \toprule  
    Network&GENIE3 &TIGRESS &NIMEFI  &PLSNET &\textbf{D3GRN}\\
    \midrule  
    Network 1&0.291 &0.302 &0.298 &0.270  &\textbf{0.373}\\
    \bottomrule  
    \end{tabular}  
    \end{threeparttable}
    %}
\end{table} 


\subsection{讨论和结论}

在~GRN~推理中, 假设相互作用是稀疏的结构是合理的,
特别是在``小~$n$~大~$p$"的情况下, 即可用样本数量少,基因数量多。
实际上稀疏性约束在机器学习中被广泛考虑。
在~GRN~中,稀疏性假设意味着每个基因只有少量的调控因子,这个假设也很合理,
本文提出的~D3GRN~方法也遵循同样的假设。
我们在~DREAM4~和~DREAM5~数据集上评估了我们的方法。
我们认为,其它基因对目标基因的调控是基多项式非线性函数的混合作用。
我们方法的实验结果也验证了这一假设,至于这个假设的理论分析需要后续的工作来支持。

另一个重要问题是关于~D3GRN~的计算复杂度。
客观地讲,~ARNI~适合于构建单元级的小型物理动态网络。
ARNI~采用的~BOLS~算法的~Moore-Penrose~伪逆运算,对于大型生物网络来说是很耗时的。
D3GRN~中采用的抽样策略使其在处理大规模~GRNs~推理时更加糟糕。
关于~ARNI~的改进空间,~D3GRN~中抽样策略中的``for"~循环是完全可以并行的,
可以在多核甚至集群中的分布式机器上同时进行。
这也值得其它方法尝试,比如用~BOMP~\cite{majumdar2009fast}来替代~BOLS~算法,这是留给未来的工作。
目前最先进的算法性能的差异性表明,
没有一种算法在所有数据集上都表现得同样出色。
然而,所有这些算法都可以应用于为元算法~(meta algorithm)提供输入,
利用``群体智慧"~(Wisdom of crowds)~来创建一个共识和可靠的社区网络~\cite{Marbach2012a,zheng2008gene}。
另外,从小网络到大网络,所有算法的性能都在下降,这或许反应了不同规模的底层调控网络的复杂性在增加。
我们的方法推进了当前的技术水平, 但要把这个问题完全解决, 还有很长的路要走。

从基因表达数据构建~GRNs~是一项重要的任务,
可以潜在地促进我们对系统生物学中疾病和癌症等基本机制的理解。
最近数据驱动的动态网络构建方法为我们推断~GRNs~提供了新的可能性。
在本研究中,我们提出了一种数据驱动的动态网络构建方法来推断基因调控网络,
该方法将每个目标基因的调控关系转化为功能分解问题,并利用揭示网络相互作用的算法~(ARNI)~来解决。
然而,传统的数据驱动的动态网络恢复方法,如~SINDy~和~ARNI~不具备构建网络的能力。
为了解决这一局限性,我们采用和基于面积的评分策略来获得最终的~GRN。
在~DREAM4~和~DREAM5~基准数据集上,~D3GRN~在~AUPR~方面的表现具有竞争力。